{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB8ToAIx1JHL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import files  # ‚úÖ For downloading\n",
        "\n",
        "# Set device\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# Load translation pipeline\n",
        "translator = pipeline(\n",
        "    \"translation\",\n",
        "    model=\"facebook/m2m100_418M\",\n",
        "    device=device,\n",
        "    batch_size=16\n",
        ")\n",
        "translator.model.config.forced_bos_token_id = translator.tokenizer.get_lang_id(\"ur\")\n",
        "\n",
        "def batch_translate_texts(sentences):\n",
        "    translations = translator(sentences, src_lang=\"en\", tgt_lang=\"ur\")\n",
        "    return [item['translation_text'] for item in translations]\n",
        "\n",
        "def translate_file(file_path):\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    if 'English Sentence' not in df.columns:\n",
        "        print(f\"‚ùå Skipping {file_path}: 'English Sentence' column not found.\")\n",
        "        return\n",
        "\n",
        "    english_sentences = df['English Sentence'].fillna(\"\").tolist()\n",
        "\n",
        "    # Break into batches\n",
        "    batch_size = 16\n",
        "    urdu_transcripts = []\n",
        "    for i in tqdm(range(0, len(english_sentences), batch_size), desc=f\"Translating {file_path}\"):\n",
        "        batch = english_sentences[i:i+batch_size]\n",
        "        urdu_transcripts.extend(batch_translate_texts(batch))\n",
        "\n",
        "    # Save results\n",
        "    df['Urdu Sentence (facebook/m2m100_418M)'] = urdu_transcripts\n",
        "\n",
        "    local_output_path = os.path.splitext(os.path.basename(file_path))[0] + '-translated.xlsx'\n",
        "    df.to_excel(local_output_path, index=False)\n",
        "    print(f\"‚úÖ Saved translated file locally: {local_output_path}\")\n",
        "\n",
        "    # ‚úÖ Download from Colab\n",
        "    files.download(local_output_path)\n",
        "\n",
        "if _name_ == \"_main_\":\n",
        "    # Upload the file manually in Colab, e.g., 'drama.xlsx'\n",
        "    files_to_translate = ['umait_dataset.xlsx']\n",
        "\n",
        "    for file in files_to_translate:\n",
        "        if os.path.exists(file):\n",
        "            translate_file(file)\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è File not found: {file}\")\n",
        "\n",
        "    print(\"üéâ Translation and download completed!\")"
      ]
    }
  ]
}